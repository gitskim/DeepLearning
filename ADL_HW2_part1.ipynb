{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ADL_HW2_part1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "AXLQrGDowIIL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "syNurw-Vwd-3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "887158c4-ee09-40c9-fef4-e0791af2dcee"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 8\n",
        "GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-192x192/*.tfrec'\n",
        "IMAGE_SIZE = [192, 192]\n",
        "VALIDATION_SPLIT = 0.19\n",
        "CLASSES = [b'daisy', b'dandelion', b'roses', b'sunflowers', b'tulips'] # do not change, maps to the labels in the data (folder names)\n",
        "filenames = tf.gfile.Glob(GCS_PATTERN)\n",
        "split = int(len(filenames) * VALIDATION_SPLIT)\n",
        "training_filenames = filenames[split:]\n",
        "validation_filenames = filenames[:split]\n",
        "print(\"Pattern matches {} data files. Splitting dataset into {} training files and {} validation files\".format(len(filenames), len(training_filenames), len(validation_filenames)))\n",
        "validation_steps = int(3670 // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
        "steps_per_epoch = int(3670 // len(filenames) * len(training_filenames)) // BATCH_SIZE\n",
        "\n",
        "def read_tfrecord(example):\n",
        "    features = {\n",
        "        \"image\": tf.FixedLenFeature((), tf.string), # tf.string means byte string\n",
        "        \"label\": tf.FixedLenFeature((), tf.string),\n",
        "        \"one_hot_label\": tf.FixedLenFeature((), tf.string)\n",
        "    }\n",
        "    example = tf.parse_single_example(example, features)\n",
        "    image = tf.image.decode_jpeg(example['image'])\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
        "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
        "    one_hot_label = tf.io.decode_raw(example['one_hot_label'], out_type=tf.uint8) # 'decode' byte string into byte list\n",
        "    one_hot_label = tf.cast(one_hot_label, tf.float32)  # convert one hot labels to floats\n",
        "    one_hot_label = tf.reshape(one_hot_label, [5])  # explicit fixed size needed on TPU\n",
        "    label = example['label']  # byte string\n",
        "    return image, label, one_hot_label\n",
        "  \n",
        "def load_dataset(filenames):  \n",
        "  # read from tfrecs\n",
        "  records = tf.data.TFRecordDataset(filenames, num_parallel_reads=32)  # this will read from multiple GCS files in parallel\n",
        "  dataset = records.map(read_tfrecord, num_parallel_calls=32)\n",
        "  return dataset\n",
        "\n",
        "def features_and_targets(image, label, one_hot_label):\n",
        "  feature = image\n",
        "  target = one_hot_label\n",
        "  return feature, target  # for training, a Keras model needs 2 items: features and targets\n",
        "\n",
        "def get_batched_dataset(filenames):\n",
        "  dataset = load_dataset(filenames)\n",
        "  dataset = dataset.map(features_and_targets, num_parallel_calls=32)\n",
        "  dataset = dataset.cache()  # This dataset fits in RAM\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(BATCH_SIZE, drop_remainder=True) # drop_remainder needed on TPU\n",
        "  dataset = dataset.prefetch(-1) # prefetch next batch while training  (-1: autotune prefetch buffer size)\n",
        "  # should shuffle too but this dataset was well shuffled on disk already\n",
        "  return dataset\n",
        "\n",
        "def get_training_dataset():\n",
        "  return get_batched_dataset(training_filenames)\n",
        "\n",
        "def get_validation_dataset():\n",
        "  return get_batched_dataset(validation_filenames)\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(192, 192, 3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "model.compile(\n",
        "  optimizer=tf.train.AdamOptimizer(),\n",
        "  loss= 'categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(get_training_dataset(), steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                      validation_data=get_validation_dataset(), validation_steps=validation_steps)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pattern matches 16 data files. Splitting dataset into 13 training files and 3 validation files\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/15\n",
            "93/93 [==============================] - 35s 374ms/step - loss: 1.1761 - acc: 0.5477 - val_loss: 0.9039 - val_acc: 0.6295\n",
            "Epoch 2/15\n",
            "93/93 [==============================] - 25s 272ms/step - loss: 0.7191 - acc: 0.7258 - val_loss: 0.7114 - val_acc: 0.7440\n",
            "Epoch 3/15\n",
            "93/93 [==============================] - 25s 273ms/step - loss: 0.4789 - acc: 0.8444 - val_loss: 0.6379 - val_acc: 0.7917\n",
            "Epoch 4/15\n",
            "93/93 [==============================] - 25s 273ms/step - loss: 0.3480 - acc: 0.8965 - val_loss: 0.5988 - val_acc: 0.7857\n",
            "Epoch 5/15\n",
            "93/93 [==============================] - 25s 271ms/step - loss: 0.2644 - acc: 0.9251 - val_loss: 0.6082 - val_acc: 0.7738\n",
            "Epoch 6/15\n",
            "93/93 [==============================] - 25s 272ms/step - loss: 0.1989 - acc: 0.9533 - val_loss: 0.6253 - val_acc: 0.7738\n",
            "Epoch 7/15\n",
            "93/93 [==============================] - 26s 274ms/step - loss: 0.1590 - acc: 0.9661 - val_loss: 0.6772 - val_acc: 0.7619\n",
            "Epoch 8/15\n",
            "93/93 [==============================] - 26s 275ms/step - loss: 0.1288 - acc: 0.9755 - val_loss: 0.7108 - val_acc: 0.7619\n",
            "Epoch 9/15\n",
            "93/93 [==============================] - 25s 274ms/step - loss: 0.1142 - acc: 0.9785 - val_loss: 0.6818 - val_acc: 0.7798\n",
            "Epoch 10/15\n",
            "93/93 [==============================] - 25s 274ms/step - loss: 0.1165 - acc: 0.9684 - val_loss: 0.6785 - val_acc: 0.7902\n",
            "Epoch 11/15\n",
            "93/93 [==============================] - 26s 274ms/step - loss: 0.1136 - acc: 0.9647 - val_loss: 0.7298 - val_acc: 0.7812\n",
            "Epoch 12/15\n",
            "93/93 [==============================] - 25s 273ms/step - loss: 0.0766 - acc: 0.9825 - val_loss: 0.7736 - val_acc: 0.7723\n",
            "Epoch 13/15\n",
            "93/93 [==============================] - 26s 274ms/step - loss: 0.0665 - acc: 0.9886 - val_loss: 0.7093 - val_acc: 0.7976\n",
            "Epoch 14/15\n",
            "93/93 [==============================] - 26s 274ms/step - loss: 0.0632 - acc: 0.9845 - val_loss: 0.7625 - val_acc: 0.8036\n",
            "Epoch 15/15\n",
            "93/93 [==============================] - 25s 274ms/step - loss: 0.0415 - acc: 0.9943 - val_loss: 0.7748 - val_acc: 0.7902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nZ2rrBUPx9bP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "d1d5b521-0c1c-4e1f-e44c-92d44aeffbf2"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 8\n",
        "GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-192x192/*.tfrec'\n",
        "IMAGE_SIZE = [192, 192]\n",
        "VALIDATION_SPLIT = 0.19\n",
        "CLASSES = [b'daisy', b'dandelion', b'roses', b'sunflowers', b'tulips'] # do not change, maps to the labels in the data (folder names)\n",
        "filenames = tf.gfile.Glob(GCS_PATTERN)\n",
        "split = int(len(filenames) * VALIDATION_SPLIT)\n",
        "training_filenames = filenames[split:]\n",
        "validation_filenames = filenames[:split]\n",
        "print(\"Pattern matches {} data files. Splitting dataset into {} training files and {} validation files\".format(len(filenames), len(training_filenames), len(validation_filenames)))\n",
        "validation_steps = int(3670 // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
        "steps_per_epoch = int(3670 // len(filenames) * len(training_filenames)) // BATCH_SIZE\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(192, 192, 3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "model.compile(\n",
        "  optimizer=tf.train.AdamOptimizer(),\n",
        "  loss= 'categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(get_training_dataset(), steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                      validation_data=get_validation_dataset(), validation_steps=validation_steps)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pattern matches 16 data files. Splitting dataset into 13 training files and 3 validation files\n",
            "Epoch 1/8\n",
            "93/93 [==============================] - 29s 312ms/step - loss: 0.8949 - acc: 0.6650 - val_loss: 0.6044 - val_acc: 0.7887\n",
            "Epoch 2/8\n",
            "93/93 [==============================] - 25s 274ms/step - loss: 0.4172 - acc: 0.8555 - val_loss: 0.6085 - val_acc: 0.7812\n",
            "Epoch 3/8\n",
            "93/93 [==============================] - 25s 272ms/step - loss: 0.2793 - acc: 0.9113 - val_loss: 0.8805 - val_acc: 0.6994\n",
            "Epoch 4/8\n",
            "93/93 [==============================] - 25s 273ms/step - loss: 0.2589 - acc: 0.9073 - val_loss: 0.6945 - val_acc: 0.7723\n",
            "Epoch 5/8\n",
            "93/93 [==============================] - 25s 273ms/step - loss: 0.1815 - acc: 0.9395 - val_loss: 0.5181 - val_acc: 0.8318\n",
            "Epoch 6/8\n",
            "93/93 [==============================] - 25s 273ms/step - loss: 0.0911 - acc: 0.9724 - val_loss: 0.5432 - val_acc: 0.8289\n",
            "Epoch 7/8\n",
            "93/93 [==============================] - 25s 273ms/step - loss: 0.0490 - acc: 0.9913 - val_loss: 0.5538 - val_acc: 0.8214\n",
            "Epoch 8/8\n",
            "93/93 [==============================] - 25s 273ms/step - loss: 0.0294 - acc: 0.9987 - val_loss: 0.5445 - val_acc: 0.8304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KFWUHgx43lKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "fdbedeac-b67f-4ac0-fced-f62f0e7735d0"
      },
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 8\n",
        "GCS_PATTERN = 'gs://flowers-public/tfrecords-jpeg-192x192/*.tfrec'\n",
        "IMAGE_SIZE = [192, 192]\n",
        "VALIDATION_SPLIT = 0.19\n",
        "CLASSES = [b'daisy', b'dandelion', b'roses', b'sunflowers', b'tulips'] # do not change, maps to the labels in the data (folder names)\n",
        "filenames = tf.gfile.Glob(GCS_PATTERN)\n",
        "split = int(len(filenames) * VALIDATION_SPLIT)\n",
        "training_filenames = filenames[split:]\n",
        "validation_filenames = filenames[:split]\n",
        "print(\"Pattern matches {} data files. Splitting dataset into {} training files and {} validation files\".format(len(filenames), len(training_filenames), len(validation_filenames)))\n",
        "validation_steps = int(3670 // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
        "steps_per_epoch = int(3670 // len(filenames) * len(training_filenames)) // BATCH_SIZE\n",
        "\n",
        "\n",
        "conv_base = VGG16(weights='imagenet',include_top=False, input_shape=(192, 192, 3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "conv_base.trainable = False\n",
        "\n",
        "model.compile(\n",
        "  optimizer=tf.train.AdamOptimizer(),\n",
        "  loss= 'categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(get_training_dataset(), steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                      validation_data=get_validation_dataset(), validation_steps=validation_steps)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pattern matches 16 data files. Splitting dataset into 13 training files and 3 validation files\n",
            "Epoch 1/8\n",
            "93/93 [==============================] - 29s 313ms/step - loss: 0.9134 - acc: 0.7087 - val_loss: 0.5708 - val_acc: 0.8006\n",
            "Epoch 2/8\n",
            "93/93 [==============================] - 25s 274ms/step - loss: 0.3396 - acc: 0.8821 - val_loss: 0.6091 - val_acc: 0.7798\n",
            "Epoch 3/8\n",
            "93/93 [==============================] - 26s 275ms/step - loss: 0.2409 - acc: 0.9140 - val_loss: 0.8149 - val_acc: 0.7440\n",
            "Epoch 4/8\n",
            "93/93 [==============================] - 26s 275ms/step - loss: 0.1881 - acc: 0.9335 - val_loss: 0.5926 - val_acc: 0.8170\n",
            "Epoch 5/8\n",
            "93/93 [==============================] - 26s 276ms/step - loss: 0.1342 - acc: 0.9509 - val_loss: 0.8816 - val_acc: 0.7604\n",
            "Epoch 6/8\n",
            "93/93 [==============================] - 26s 276ms/step - loss: 0.1271 - acc: 0.9556 - val_loss: 0.6480 - val_acc: 0.8214\n",
            "Epoch 7/8\n",
            "93/93 [==============================] - 26s 276ms/step - loss: 0.1309 - acc: 0.9503 - val_loss: 0.9310 - val_acc: 0.7738\n",
            "Epoch 8/8\n",
            "93/93 [==============================] - 26s 276ms/step - loss: 0.0629 - acc: 0.9812 - val_loss: 0.6531 - val_acc: 0.8363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pOdyjuZT5zm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}