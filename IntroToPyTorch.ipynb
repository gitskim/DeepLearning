{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroToPyTorch",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlHjkcDCjyYH",
        "colab_type": "text"
      },
      "source": [
        "# Tensors\n",
        "\n",
        "* A generalization of matrices\n",
        "\n",
        "## Vector\n",
        "\n",
        "* One dimensional tensors\n",
        "\n",
        "## Matrix\n",
        "\n",
        "* 2-dimensional tensors\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLO4lE2okuZj",
        "colab_type": "text"
      },
      "source": [
        "# Basic Single Layer Neural Networks With Vectors\n",
        "\n",
        "\n",
        "NOTE:\n",
        "\n",
        "torch.mm is more strict about the input shape as opposed to torch.matmul, which supports broadcasting, being able to give you a wrong output. \n",
        "\n",
        "\n",
        "* weights.reshape(a, b) - a new tensor with the same data as weights, but sometimes the actual data in memory isn't being changed and some other times it gives you a clone.\n",
        "* weights.reshape_(a, b) - the underscore is an in-place operation. It's changing only the tensor in memory without touching the data. \n",
        "  If you request the size that is more or less than the original shape, you can cut off the\n",
        "  original data\n",
        "* weights.view(a, b) - always returns a new data without touching any of the data in memory. For an impossible shape, it returns an error. \n",
        "\n",
        "torch.mm(features, weights.view(5, 1) is equivalent to torch.sum(features * weights) and (features * weights).sum(), \n",
        "only if it's using vectors not matrices, but using torch function is most efficient.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku7feFA3QFje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqTHvq84k50Z",
        "colab_type": "code",
        "outputId": "b9ea7a71-a948-47bf-9962-e8c01b6f5031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# To get the output as a probability\n",
        "def sigmoid_activation(x):\n",
        "  return 1/(1 + torch.exp(-x))\n",
        "\n",
        "\n",
        "# Set the random seed so things are predictable\n",
        "torch.manual_seed(7)\n",
        "\n",
        "# Features are 5 random normal variable\n",
        "# 1 row and 5 columns \n",
        "features = torch.randn((1, 5))\n",
        "\n",
        "# create another tensor with the same shape as input\n",
        "weights = torch.randn_like(features)\n",
        "\n",
        "bias = torch.randn((1, 1))\n",
        "\n",
        "print(features, weights, bias)\n",
        "\n",
        "# To calculate the output of this network using the weights and bias\n",
        "\n",
        "result = sigmoid_activation(torch.mm(features, weights.view(5, 1)) + bias)\n",
        "print(result)\n",
        "      "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]]) tensor([[-0.8948, -0.3556,  1.2324,  0.1382, -1.6822]]) tensor([[0.3177]])\n",
            "tensor([[0.1595]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZoPykoEvonD",
        "colab_type": "text"
      },
      "source": [
        "# Basic Multilayer Neural Network With Matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phgnhkonvuBu",
        "colab_type": "code",
        "outputId": "12f77a8b-fa36-472d-b7e9-ae150d733c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.manual_seed(7)\n",
        "\n",
        "features = torch.randn((1, 3))\n",
        "n_input = features.shape[1]\n",
        "n_hidden = 2\n",
        "n_output = 1\n",
        "\n",
        "# question: why does it not have (), but B1's do?\n",
        "W1 = torch.randn((n_input, n_hidden))\n",
        "W2 = torch.randn((n_hidden, n_output))\n",
        "\n",
        "B1 = torch.randn((1, n_hidden))\n",
        "B2 = torch.randn((1, n_output))\n",
        "\n",
        "hidden_output = sigmoid_activation(torch.mm(features, W1) + B1)\n",
        "output = sigmoid_activation(torch.mm(hidden_output, W2) + B2)\n",
        "print(output)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3171]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKKs2hJKyiBV",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network W/ MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp4VuNwIyhM7",
        "colab_type": "code",
        "outputId": "be5daca9-9cf5-4dab-9c38-dc8b0507f0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        }
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "import helper\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "'''\n",
        "Transforms: it does image transformations\n",
        "\n",
        "Compose: common image transformations can be chanined together using Compose.\n",
        "'''\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('./', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "!wget https://github.com/gitskim/Pasion/raw/master/diving.mat\n",
        "!wget https://raw.githubusercontent.com/gitskim/Pasion/master/Diving.txt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:03, 2556664.97it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 58340.20it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:01, 955371.27it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 22135.80it/s]            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:02, 4343512.60it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 57314.80it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:01, 959167.59it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 22065.86it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n",
            "--2019-08-20 04:09:55--  https://github.com/gitskim/Pasion/raw/master/diving.mat\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/gitskim/Pasion/master/diving.mat [following]\n",
            "--2019-08-20 04:09:56--  https://raw.githubusercontent.com/gitskim/Pasion/master/diving.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9591612 (9.1M) [application/octet-stream]\n",
            "Saving to: ‘diving.mat’\n",
            "\n",
            "diving.mat          100%[===================>]   9.15M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-08-20 04:10:00 (66.5 MB/s) - ‘diving.mat’ saved [9591612/9591612]\n",
            "\n",
            "--2019-08-20 04:10:01--  https://raw.githubusercontent.com/gitskim/Pasion/master/Diving.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6139 (6.0K) [text/plain]\n",
            "Saving to: ‘Diving.txt’\n",
            "\n",
            "Diving.txt          100%[===================>]   6.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-20 04:10:02 (107 MB/s) - ‘Diving.txt’ saved [6139/6139]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3Qt2mK3NkuJ",
        "colab_type": "code",
        "outputId": "2207967f-e9c7-4ca4-e68c-d0c159b79a82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(type(images))\n",
        "print(type(labels))\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJnL8kECPRR4",
        "colab_type": "code",
        "outputId": "1b148176-ee93-42c5-9c0f-798dde30e7c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Hc5IVLPbwP",
        "colab_type": "code",
        "outputId": "cb5f3248-3863-478e-d570-cd5b50e5c94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# flatten the input images\n",
        "# question: how does it pack and unpack using view, so that it retreives exactly same image?\n",
        "reshaped_images = images.view(64, 784)\n",
        "print(reshaped_images.shape)\n",
        "plt.imshow(reshaped_images[1].view(28, 28).numpy(), cmap='Greys_r');\n",
        "\n",
        "input_size = 64\n",
        "input_dim = 784\n",
        "hidden_state_size = 256\n",
        "output_size = 10\n",
        "W1 = torch.randn((input_dim, hidden_state_size))\n",
        "# Question: how can you create a bias vector not a matrix to add to the matrix?\n",
        "B1 = torch.randn(hidden_state_size)\n",
        "\n",
        "W2 = torch.randn((hidden_state_size, output_size))\n",
        "B2 = torch.randn((output_size))\n",
        "\n",
        "W1_calc = sigmoid_activation(torch.mm(reshaped_images, W1))\n",
        "\n",
        "result = sigmoid_activation(torch.mm(W1_calc, W2) + B2)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 784])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 253,
              "height": 250
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtrG-Zh8riOE",
        "colab_type": "text"
      },
      "source": [
        "* if no dimension is mentioned, it will sum every value in the matrix resulting in one value. \n",
        "* if dimension is 0, it sums over rows, so the result is a vector with total column number of entries.\n",
        "Then each row will be divided by a different number.\n",
        "* if dimension is 1, it sums over columns, so the result is a vector with total row number of entries. Then each column will **not be able to be divided by a different number** this column vector, because PyTorch doesn't enable division across rows, but only columns by default, which is called **broadcasting**. If you want to divide a matrix by a column vector, it has to be modified  to be a matrix. e.g. (9) should be modified to (9, 1) to divide the matrix of (9, anyint)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBxLO08GrfWe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SUX01UXgYIV",
        "colab_type": "code",
        "outputId": "31e486bd-d24f-46ca-9b83-26edcf56ad60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "# see how summing in different dimension results into a different result\n",
        "arr = np.array([[2, 3, 5], [5, 3, 2]], dtype=np.float)\n",
        "arr = torch.tensor(arr)\n",
        "print(arr)\n",
        "\n",
        "msum = torch.sum(arr, dim=0)\n",
        "print(msum.shape)\n",
        "res = arr / msum\n",
        "print(res)\n",
        "\n",
        "# softmax\n",
        "def softmax(x):\n",
        "  print(\"inside softmax: %d\", x.shape)\n",
        "  denominator = torch.sum(torch.exp(x), dim=1)\n",
        "  denominator_real = denominator.view(-1, 1)\n",
        "  \n",
        "  # question: what is the difference between (64) and (64, 1) visually?\n",
        "  \n",
        "  return torch.exp(x) / denominator_real\n",
        "  \n",
        "  \n",
        "prob = softmax(result)\n",
        "\n",
        "# do double check by summing over each row and making sure it is 1. \n",
        "print(torch.sum(prob, dim=1))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2., 3., 5.],\n",
            "        [5., 3., 2.]], dtype=torch.float64)\n",
            "torch.Size([3])\n",
            "tensor([[0.2857, 0.5000, 0.7143],\n",
            "        [0.7143, 0.5000, 0.2857]], dtype=torch.float64)\n",
            "inside softmax: %d torch.Size([64, 10])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
            "        1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-5sPEsgwLAb",
        "colab_type": "text"
      },
      "source": [
        "# Building Networks With PyTorch\n",
        "\n",
        "1. You need to subclass it from **nn.Module**\n",
        "2. You need to call **nn.Module**'s superclass\n",
        "\n",
        "```c\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "```\n",
        "\n",
        "3. Linear layer is the combination of weights and bias matrices. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSkHsy2NwfqX",
        "colab_type": "code",
        "outputId": "c31a699d-4714-49a3-a9d0-deb18b49ded0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self, hidden1_input_size, hidden1_output_size, hidden2_output_size):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(hidden1_input_size, hidden1_output_size)\n",
        "    self.output = nn.Linear(hidden1_output_size, hidden2_output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "  \n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.hidden(x)\n",
        "    x = self.sigmoid(x)\n",
        "    x = self.output(x)\n",
        "    x = self.softmax(x)\n",
        "    \n",
        "    return x\n",
        "   \n",
        "    \n",
        "model = Network(784, 256, 10)\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhZoKMKF2jfQ",
        "colab_type": "text"
      },
      "source": [
        "Another way to do this is to call <code>Sigmoid</code> from <code>import torch.nn.functional as F</code>. If you use it from nn, it creates objects and classes, but if you use it from functional, it won't create any objects and classes, because it simply does it functionally. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOsdzMyJ3QR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Inputs to hidden layer linear transformation\n",
        "        self.hidden = nn.Linear(784, 256)\n",
        "        # Output layer, 10 units - one for each digit\n",
        "        self.output = nn.Linear(256, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Hidden layer with sigmoid activation\n",
        "        x = F.sigmoid(self.hidden(x))\n",
        "        # Output layer with softmax activation\n",
        "        x = F.softmax(self.output(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0yAZh9aOOF3",
        "colab_type": "text"
      },
      "source": [
        "# Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0p5sUrFOQos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e0969bc9-7ed3-4c99-ef4f-3501d42a63ac"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#question - learn more about next and iter\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "#labels = one_hot_encoding(labels, 10)\n",
        "reshaped_images = images.view(images.shape[0], 784)\n",
        "print(reshaped_images.shape)\n",
        "prob = model(reshaped_images)\n",
        "print(prob.shape)\n",
        "\n",
        "loss = criterion(prob, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 784])\n",
            "torch.Size([64, 10])\n",
            "tensor(2.2795, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRuGkGRqAA2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "27ca22f8-bcca-4dfc-f589-b8ac408d8177"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "#question - learn more about next and iter\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "#labels = one_hot_encoding(labels, 10)\n",
        "reshaped_images = images.view(images.shape[0], 784)\n",
        "print(reshaped_images.shape)\n",
        "prob = model(reshaped_images)\n",
        "print(prob.shape)\n",
        "\n",
        "loss = criterion(prob, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 784])\n",
            "torch.Size([64, 10])\n",
            "tensor(2.3261, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuXWJUiScD1p",
        "colab_type": "text"
      },
      "source": [
        "# Autograd\n",
        "\n",
        "y = x^2\n",
        "\n",
        "z = mean(y)\n",
        "\n",
        "dz/dx = question: how to calculate it? x/2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjqaQO_ycFoL",
        "colab_type": "code",
        "outputId": "6bfd1c31-1314-4ebf-a845-55d63d87f852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "x = torch.randn([2, 2], requires_grad=True)\n",
        "y = x ** 2\n",
        "z = y.mean()\n",
        "\n",
        "print(y)\n",
        "print(x.grad)\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.0300, 1.4417],\n",
            "        [0.0463, 0.0328]], grad_fn=<PowBackward0>)\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHj6lz6UGF1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "ee40dda2-0156-4f4e-ebaf-adb1d4c4c923"
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.0744,  0.4848],\n",
            "        [ 0.2476, -0.0179]])\n",
            "tensor([[-1.0744,  0.4848],\n",
            "        [ 0.2476, -0.0179]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnEhnGVjVFYb",
        "colab_type": "text"
      },
      "source": [
        "# Training the network\n",
        "\n",
        "you need to send what you want to do gradient descent on. e.g. you want to update model's parameters, so you do the following and specify the learning rate. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcSHbZdjVMF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "39b34b68-0d2b-4775-8c7c-79b10a9eee10"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "print(model)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8dK74mCarhv",
        "colab_type": "text"
      },
      "source": [
        "1. Make a forward pass through the network\n",
        "2. Use the network output to calculate the loss\n",
        "3. Perform a backward pass through the network to calculate the gradients\n",
        "4. Take a step with the optimizer to update the weights\n",
        "\n",
        "The folloing shows how the first linear layer's weight changes as the gradient descent is performed just once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yOnjsMNa-Iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "e87573c9-8f4c-407f-c634-9ce3a0c66181"
      },
      "source": [
        "# 1\n",
        "images, labels = next(iter(trainloader))\n",
        "prob = model(images.view(-1, 784))\n",
        "\n",
        "# 2\n",
        "loss = criterion(prob, labels)\n",
        "print(\"Initial weigths shape: -, weights : - \", model[0], model[0].weight)\n",
        "\n",
        "# 3\n",
        "loss.backward()\n",
        "print(\"Gradients: - \", model[0].weight.grad)\n",
        "\n",
        "# 4\n",
        "optimizer.step()\n",
        "print(\"After updates: - \", model[0].weight)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weigths shape: -, weights : -  Linear(in_features=784, out_features=128, bias=True) Parameter containing:\n",
            "tensor([[-0.0008,  0.0251,  0.0348,  ..., -0.0287, -0.0012, -0.0184],\n",
            "        [-0.0053,  0.0109, -0.0030,  ...,  0.0240,  0.0301, -0.0075],\n",
            "        [-0.0198, -0.0251,  0.0172,  ...,  0.0175,  0.0027,  0.0302],\n",
            "        ...,\n",
            "        [ 0.0156, -0.0184, -0.0172,  ..., -0.0302,  0.0027, -0.0034],\n",
            "        [-0.0337, -0.0024,  0.0079,  ...,  0.0341, -0.0148,  0.0222],\n",
            "        [ 0.0348, -0.0125, -0.0202,  ..., -0.0322, -0.0153, -0.0341]],\n",
            "       requires_grad=True)\n",
            "Gradients: -  tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
            "        [ 0.0009,  0.0009,  0.0009,  ...,  0.0009,  0.0009,  0.0009],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0097,  0.0097,  0.0097,  ...,  0.0097,  0.0097,  0.0097],\n",
            "        [-0.0110, -0.0110, -0.0110,  ..., -0.0110, -0.0110, -0.0110]])\n",
            "After updates: -  Parameter containing:\n",
            "tensor([[-0.0008,  0.0251,  0.0348,  ..., -0.0287, -0.0012, -0.0184],\n",
            "        [-0.0053,  0.0109, -0.0031,  ...,  0.0240,  0.0301, -0.0075],\n",
            "        [-0.0199, -0.0251,  0.0171,  ...,  0.0175,  0.0027,  0.0302],\n",
            "        ...,\n",
            "        [ 0.0156, -0.0184, -0.0172,  ..., -0.0302,  0.0027, -0.0034],\n",
            "        [-0.0338, -0.0025,  0.0078,  ...,  0.0340, -0.0149,  0.0222],\n",
            "        [ 0.0349, -0.0124, -0.0201,  ..., -0.0321, -0.0152, -0.0340]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJBrH95QcxmH",
        "colab_type": "text"
      },
      "source": [
        "## Training Multiple Epochs (Putting it all together)\n",
        "\n",
        "**VERY IMPORTANT**: When you have multiple passes to update the **same** parameters, gradients are **accumulated**. Therefore for each pass, you need to call <code>optimizer.zero_grad()</code>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSIbaVvqdpp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "abcc56a2-cdc4-4a56-a0db-0d866af9d784"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), 0.003)\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  current_loss = 0\n",
        "  \n",
        "  for images, labels in trainloader:\n",
        "    # 0. clean out the optimizer\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # 1. Forward pass\n",
        "    # Question: Figure out why I can't use images.reshape_((-1, 784))\n",
        "    prob = model(images.view(-1, 784))\n",
        "    \n",
        "    # 2. calculate loss\n",
        "    loss = criterion(prob, labels)\n",
        "    current_loss += loss.item()/len(trainloader)\n",
        "    \n",
        "    # 3. calculate gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # 4. Update parameters based on gradients\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "  print(\"epoch: %d, current_loss: %f\", epoch, current_loss)\n",
        "    "
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: %d, current_loss: %f 0 1.9098771924911533\n",
            "epoch: %d, current_loss: %f 1 0.8632997169868266\n",
            "epoch: %d, current_loss: %f 2 0.5284624109898546\n",
            "epoch: %d, current_loss: %f 3 0.42913611832140347\n",
            "epoch: %d, current_loss: %f 4 0.3850373007309463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHtHmm7Wm1Wv",
        "colab_type": "text"
      },
      "source": [
        "# Verification Step\n",
        "\n",
        "This step is equivalent to Keras' <code>predict</code>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1gxUr3Fc9-Y",
        "colab_type": "code",
        "outputId": "0403a46d-2e10-4086-e4d8-7f8b41d60581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    \n",
        "images, labels = next(iter(trainloader))\n",
        "img = images[0].view(1, 784)\n",
        "\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "  log_ps = model(img)\n",
        "  \n",
        "\n",
        "output = torch.exp(log_ps)\n",
        "\n",
        "view_classify(img, output)\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHECAYAAAAOFHoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 423,
              "height": 226
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdVGvV2_3VLu",
        "colab_type": "text"
      },
      "source": [
        "NOTE: It turns out that networks tend to train a lot faster using ReLu instead of tanh or sigmoid activation functions ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCZqjOQB5aWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import subprocess\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pickle\n",
        "import scipy.io as sio\n",
        "\n",
        "# TODO:\n",
        "#ANNOTATION_FILE = '/home/suhyunkim011/Pasion/Diving.txt'\n",
        "ANNOTATION_FILE = 'Diving.txt'\n",
        "\n",
        "#MAT_FILE = '/home/suhyunkim011/Pasion/diving.mat'\n",
        "MAT_FILE = 'diving.mat'\n",
        "\n",
        "def get_pose_labels2():\n",
        "    # move the pictures to a certain directory and create labels\n",
        "    contents = sio.loadmat(MAT_FILE)\n",
        "    # print(len(contents))\n",
        "    tracked = contents['boxes_tracked_wholevideo']\n",
        "    # print(tracked)\n",
        "    # print(len(tracked))\n",
        "    # (298387, 107)\n",
        "    # print(tracked.shape)\n",
        "\n",
        "    # print(tracked[0].shape)\n",
        "\n",
        "    # batchsize = 298387; timesteps = 202; shape = 104;\n",
        "    arr_frame = []\n",
        "    arr_score = np.array([])\n",
        "    arr_score_flat = []\n",
        "    arr_difficulty = np.array([])\n",
        "    arr_difficulty_flat = []\n",
        "\n",
        "    with open(ANNOTATION_FILE) as filename:\n",
        "        max_counter = 202\n",
        "        group_counter = 0\n",
        "        one_group_counter = 0\n",
        "        max_one_group_counter = 202\n",
        "        supposed_to_be_counter = 0\n",
        "        for line in filename:\n",
        "            # print(line)\n",
        "            if '#' in line:\n",
        "                continue\n",
        "\n",
        "            if 'A' in line:\n",
        "\n",
        "                group_counter += 1\n",
        "                line_arr = line.split()\n",
        "                # print(line_arr[0])\n",
        "                # print(line_arr[1])\n",
        "                start = -1\n",
        "                end = -1\n",
        "\n",
        "                for i in range(0, 2):\n",
        "                    if i == 0:\n",
        "                        start = line_arr[0]\n",
        "                        start = int(start)\n",
        "\n",
        "                    elif i == 1:\n",
        "                        end = line_arr[1]\n",
        "                        end = int(end)\n",
        "\n",
        "                start = start - 1\n",
        "\n",
        "                pose_group = np.zeros([202, 104])\n",
        "\n",
        "                for i in range(start, end + 1):\n",
        "                    supposed_to_be_counter += 1\n",
        "                    converted = tracked[i][:104]\n",
        "                    pose_group[one_group_counter, :] = converted\n",
        "                    one_group_counter += 1\n",
        "\n",
        "                if one_group_counter > max_one_group_counter:\n",
        "                    max_one_group_counter = one_group_counter\n",
        "                    print(\"-------------*********-----------------WARNING-------------*********-----------------: %d\", one_group_counter)\n",
        "                # len(pose_group): 169; one_group_counter: 169; max_one_group_counter: 202\n",
        "\n",
        "                # print(pose_group)\n",
        "                arr_frame.append(pose_group)  # figure out why it worked when I put it above the if one_group_counter > max_one_group_counter:\n",
        "                one_group_counter = 0\n",
        "\n",
        "            if 'Score' in line:\n",
        "                line_arr = line.split()\n",
        "                arr_sub_total_score = np.empty(max_counter)\n",
        "                arr_sub_total_score.fill(line_arr[2])\n",
        "\n",
        "                arr_sub_difficulty_score = np.empty(max_counter)\n",
        "                arr_sub_difficulty_score.fill(line_arr[3])\n",
        "\n",
        "                arr_score = np.append(arr_score, arr_sub_total_score)\n",
        "                arr_difficulty = np.append(arr_difficulty, arr_sub_difficulty_score)\n",
        "                # print(arr_sub_total_score)\n",
        "\n",
        "                arr_score_flat.append(float(line_arr[2]))\n",
        "                arr_difficulty_flat.append(float(line_arr[3]))\n",
        "\n",
        "        # print(f'arr_frame: {len(arr_frame)}, arr_score_flat: {len(arr_score_flat)}, arr_difficulty_concat: {len(arr_difficulty_flat)}')\n",
        "        # print(f'arr_frame: {len(arr_frame)}')\n",
        "        # print(arr_frame[71])\n",
        "        print(np.array(arr_frame).shape)\n",
        "    return np.array(arr_frame), np.array(arr_score_flat), arr_difficulty_flat\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}