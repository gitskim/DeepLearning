{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will classify images from the MNIST-dataset. The datasets consist of (TODO:). The images need to be preprocessed to be normaliezd and one-hot encoded. \n",
    "\n",
    "## Loading Data\n",
    "\n",
    "By importing input_data from tensorflow, you can simply call the function read_data_sets() and decide what folder to save the data, in this case, \"MNIST_data/\". one_hot is set to be false, because I want to show the one_hot encoding process manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "The shape of train data is (55000, 784). There are 55000 number of flattened iagme data (28 x 28 = 784). It needs to be reshaped to be 2 dimensional. We will have the input data go thorugh the tensor of shape (0, 784) and be reshaped into 28 x 28 automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "x_reshaped = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution layer\n",
    "The following function defines creating a convolution layer including the max pool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_conv_layer(data, num_channels, num_filters, filter_shape, pool_shape, unique_name):\n",
    "    # set up the input filter shape for 2 dimensional data\n",
    "    conv_filter_shape = [filter_shape[0], filter_shape[1], num_channels, num_filters]\n",
    "    \n",
    "    # created weights and bias for the filter\n",
    "    # tf.Variable(<initial-value>, name=<optional-name>)\n",
    "    \n",
    "    # truncated_normal(shape, mean=0.0, stddev=1.0, dtype=dtypes.float32, seed=None, name=None) \n",
    "    # outputs random values from a truncated normal distribution.\n",
    "    weights = tf.Variable(tf.truncated_normal(conv_filter_shape, stddev=0.03), name='w_' + unique_name)\n",
    "    bias = tf.Variable(tf.truncated_normal([nu_filters]), name='b_' + unique_name)\n",
    "    \n",
    "    # set up the convolutional layer operation\n",
    "    # Computes a 2-D convolution given 4-D input and filter tensors.\n",
    "    # Given an input tensor of shape [batch, in_height, in_width, in_channels] and a filter / kernel tensor of shape \n",
    "    # [filter_height, filter_width, in_channels, out_channels], this op performs the following:\n",
    "    # 1. Flattens the filter to a 2-D matrix with shape [filter_height * filter_width * in_channels, output_channels].\n",
    "    # 2. Extracts image patches from the input tensor to form a virtual tensor of shape \n",
    "    # [batch, out_height, out_width, filter_height * filter_width * in_channels].\n",
    "    # 3. For each patch, right-multiplies the filter matrix and the image patch vector.\n",
    "    conv_out_layer = tf.nn.conv2d(data, weights, [1, 1, 1, 1], padding='SAME')\n",
    "    \n",
    "    # add the bias to the output of the convolutional layer\n",
    "    conv_out_layer += bias\n",
    "    \n",
    "    # apply a non-linear activation (ReLU)\n",
    "    conv_out_layer = tf.nn.relu(conv_out_layer)\n",
    "    \n",
    "    # apply max pooling\n",
    "    # ksize is the argument which defines the size of the max pooling window (i.e. the area over which the maximum is\n",
    "    # calculated).  It must be 4D to match the convolution - in this case, for each image we want to use a 2 x 2 area\n",
    "    # applied to each channel\n",
    "    ksize = [1, pool_shape[0], pool_shape[1], 1]\n",
    "    \n",
    "    # strides defines how the max pooling area moves through the image - a stride of 2 in the x direction will lead to\n",
    "    # max pooling areas starting at x=0, x=2, x=4 etc. through your image.  If the stride is 1, we will get max pooling\n",
    "    # overlapping previous max pooling areas (and no reduction in the number of parameters).  In this case, we want\n",
    "    # to do strides of 2 in the x and y directions.\n",
    "    strides = [1, 2, 2, 1]\n",
    "    \n",
    "    out_layer = tf.nn.max_pool(conv_out_layer, ksize=ksize, strides=strides, padding='SAME')\n",
    "    \n",
    "    return out_layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
