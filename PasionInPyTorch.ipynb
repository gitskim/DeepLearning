{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PasionInPyTorch.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R6Dg3hILwpt",
        "colab_type": "code",
        "outputId": "0bc1d7b2-f02f-4d3c-e872-291b229f85f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "!wget https://github.com/gitskim/Pasion/raw/master/diving.mat\n",
        "!wget https://raw.githubusercontent.com/gitskim/Pasion/master/Diving.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-21 09:51:13--  https://github.com/gitskim/Pasion/raw/master/diving.mat\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/gitskim/Pasion/master/diving.mat [following]\n",
            "--2019-08-21 09:51:15--  https://raw.githubusercontent.com/gitskim/Pasion/master/diving.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9591612 (9.1M) [application/octet-stream]\n",
            "Saving to: ‘diving.mat.1’\n",
            "\n",
            "diving.mat.1        100%[===================>]   9.15M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-08-21 09:51:16 (63.7 MB/s) - ‘diving.mat.1’ saved [9591612/9591612]\n",
            "\n",
            "--2019-08-21 09:51:19--  https://raw.githubusercontent.com/gitskim/Pasion/master/Diving.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6139 (6.0K) [text/plain]\n",
            "Saving to: ‘Diving.txt.1’\n",
            "\n",
            "Diving.txt.1        100%[===================>]   6.00K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-08-21 09:51:19 (83.3 MB/s) - ‘Diving.txt.1’ saved [6139/6139]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP4jyZ1-Zd5s",
        "colab_type": "code",
        "outputId": "5dd499e4-e69c-4656-e738-6d2d06da42b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import subprocess\n",
        "import numpy as np\n",
        "import os.path\n",
        "import pickle\n",
        "import scipy.io as sio\n",
        "\n",
        "# TODO:\n",
        "# ANNOTATION_FILE = '/home/suhyunkim011/Pasion/Diving.txt'\n",
        "ANNOTATION_FILE = 'Diving.txt'\n",
        "\n",
        "# MAT_FILE = '/home/suhyunkim011/Pasion/diving.mat'\n",
        "MAT_FILE = 'diving.mat'\n",
        "\n",
        "\n",
        "def get_pose_labels2():\n",
        "    # move the pictures to a certain directory and create labels\n",
        "    contents = sio.loadmat(MAT_FILE)\n",
        "    # print(len(contents))\n",
        "    tracked = contents['boxes_tracked_wholevideo']\n",
        "    # print(tracked)\n",
        "    # print(len(tracked))\n",
        "    # (298387, 107)\n",
        "    # print(tracked.shape)\n",
        "\n",
        "    # print(tracked[0].shape)\n",
        "\n",
        "    # batchsize = 298387; timesteps = 202; shape = 104;\n",
        "    arr_frame = []\n",
        "    arr_score = np.array([])\n",
        "    arr_score_flat = []\n",
        "    arr_difficulty = np.array([])\n",
        "    arr_difficulty_flat = []\n",
        "\n",
        "    with open(ANNOTATION_FILE) as filename:\n",
        "        max_counter = 202\n",
        "        group_counter = 0\n",
        "        one_group_counter = 0\n",
        "        supposed_to_be_counter = 0\n",
        "        for line in filename:\n",
        "            #print(line)\n",
        "            if '#' in line:\n",
        "                continue\n",
        "\n",
        "            if 'A' in line:\n",
        "\n",
        "                group_counter += 1\n",
        "                line_arr = line.split()\n",
        "                # print(line_arr[0])\n",
        "                # print(line_arr[1])\n",
        "                start = -1\n",
        "                end = -1\n",
        "\n",
        "                for i in range(0, 2):\n",
        "                    if i == 0:\n",
        "                        start = line_arr[0]\n",
        "                        start = int(start)\n",
        "\n",
        "                    elif i == 1:\n",
        "                        end = line_arr[1]\n",
        "                        end = int(end)\n",
        "\n",
        "                start = start - 1\n",
        "\n",
        "                pose_group = np.zeros([202, 104])\n",
        "\n",
        "                for i in range(start, end + 1):\n",
        "                    supposed_to_be_counter += 1\n",
        "                    converted = tracked[i][:104]\n",
        "                    #print(f\"one_group_counter: {one_group_counter}, converted.shape: {converted.shape}\")\n",
        "                    \n",
        "                    pose_group[one_group_counter, :] = converted\n",
        "                 \n",
        "                    one_group_counter += 1\n",
        "\n",
        "                if one_group_counter > max_counter:\n",
        "                    max_counter = one_group_counter\n",
        "                    print(\"-------------*********---------WARNING: Max counter changed: %d-------------*********\",\n",
        "                          max_counter)\n",
        "                # len(pose_group): 169; one_group_counter: 169; max_one_group_counter: 202\n",
        "\n",
        "                # print(pose_group)\n",
        "                arr_frame.append(\n",
        "                    pose_group)  # figure out why it worked when I put it above the if one_group_counter > max_one_group_counter:\n",
        "                one_group_counter = 0\n",
        "\n",
        "            if 'Score' in line:\n",
        "                line_arr = line.split()\n",
        "                arr_sub_total_score = np.empty(max_counter)\n",
        "                arr_sub_total_score.fill(float(line_arr[2]))\n",
        "\n",
        "                arr_sub_difficulty_score = np.empty(max_counter)\n",
        "                arr_sub_difficulty_score.fill(float(line_arr[3]))\n",
        "\n",
        "                arr_score = np.append(arr_score, arr_sub_total_score)\n",
        "                arr_difficulty = np.append(arr_difficulty, arr_sub_difficulty_score)\n",
        "                # print(arr_sub_total_score)\n",
        "\n",
        "                arr_score_flat.append(float(line_arr[2]))\n",
        "                arr_difficulty_flat.append(float(line_arr[3]))\n",
        "\n",
        "        # print(f'arr_frame: {len(arr_frame)}, arr_score_flat: {len(arr_score_flat)}, arr_difficulty_concat: {len(arr_difficulty_flat)}')\n",
        "        # print(f'arr_frame: {len(arr_frame)}')\n",
        "        # print(arr_frame[71])\n",
        "        print(np.array(arr_frame).shape)\n",
        "    return np.array(arr_frame), np.array(arr_score_flat), arr_difficulty_flat\n",
        "\n",
        "\n",
        "arr_frames, arr_scores, arr_difficulty = get_pose_labels2()\n",
        "print(arr_frames.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(159, 202, 104)\n",
            "(159, 202, 104)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkj9UM-QUxbb",
        "colab_type": "text"
      },
      "source": [
        "NOTE: drop_out probability is only used if the number of layers is greater than 1. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qdj2k5kWkEX",
        "colab_type": "code",
        "outputId": "a8f7d2f3-958f-442e-ceff-f832b223d2e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "def pearsonr(x, y):\n",
        "    \"\"\"\n",
        "    Mimics `scipy.stats.pearsonr`\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    x : 1D torch.Tensor\n",
        "    y : 1D torch.Tensor\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    r_val : float\n",
        "        pearsonr correlation coefficient between x and y\n",
        "    \n",
        "    Scipy docs ref:\n",
        "        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html\n",
        "    \n",
        "    Scipy code ref:\n",
        "        https://github.com/scipy/scipy/blob/v0.19.0/scipy/stats/stats.py#L2975-L3033\n",
        "    Example:\n",
        "        >>> x = np.random.randn(100)\n",
        "        >>> y = np.random.randn(100)\n",
        "        >>> sp_corr = scipy.stats.pearsonr(x, y)[0]\n",
        "        >>> th_corr = pearsonr(torch.from_numpy(x), torch.from_numpy(y))\n",
        "        >>> np.allclose(sp_corr, th_corr)\n",
        "    \"\"\"\n",
        "    mean_x = torch.mean(x)\n",
        "    mean_y = torch.mean(y)\n",
        "    xm = x.sub(mean_x)\n",
        "    ym = y.sub(mean_y)\n",
        "    r_num = xm.dot(ym)\n",
        "    r_den = torch.norm(xm, 2) * torch.norm(ym, 2)\n",
        "    r_val = r_num / r_den\n",
        "    return r_val\n",
        "\n",
        "def corrcoef(x):\n",
        "    \"\"\"\n",
        "    Mimics `np.corrcoef`\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    x : 2D torch.Tensor\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    c : torch.Tensor\n",
        "        if x.size() = (5, 100), then return val will be of size (5,5)\n",
        "\n",
        "    Numpy docs ref:\n",
        "        https://docs.scipy.org/doc/numpy/reference/generated/numpy.corrcoef.html\n",
        "    Numpy code ref: \n",
        "        https://github.com/numpy/numpy/blob/v1.12.0/numpy/lib/function_base.py#L2933-L3013\n",
        "\n",
        "    Example:\n",
        "        >>> x = np.random.randn(5,120)\n",
        "        # result is a (5,5) matrix of correlations between rows\n",
        "        >>> np_corr = np.corrcoef(x)\n",
        "        >>> th_corr = corrcoef(torch.from_numpy(x))\n",
        "        >>> np.allclose(np_corr, th_corr.numpy())\n",
        "        # [out]: True\n",
        "    \"\"\"\n",
        "    # calculate covariance matrix of rows\n",
        "    mean_x = torch.mean(x, 1)\n",
        "    xm = x.sub(mean_x.expand_as(x))\n",
        "    c = xm.mm(xm.t())\n",
        "    c = c / (x.size(1) - 1)\n",
        "\n",
        "    # normalize covariance matrix\n",
        "    d = torch.diag(c)\n",
        "    stddev = torch.pow(d, 0.5)\n",
        "    c = c.div(stddev.expand_as(c))\n",
        "    c = c.div(stddev.expand_as(c).t())\n",
        "\n",
        "    # clamp between -1 and 1\n",
        "    # probably not necessary but numpy does it\n",
        "    c = torch.clamp(c, -1.0, 1.0)\n",
        "\n",
        "    return c\n",
        "  \n",
        "\n",
        "sequence_length = 202\n",
        "class PoseLSTM(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size=104, hidden_size=256, num_layers=2, drop_prob=0.5, lr=0.001, output_size=159):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.drop_prob = drop_prob\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.lr = lr\n",
        "    self.input_size = input_size\n",
        "    self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size, num_layers=self.num_layers, dropout=self.drop_prob, batch_first=True)\n",
        "    # why is there an extra dropout layer when there is dropout in lstm?\n",
        "    self.dropout = nn.Dropout(drop_prob)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    \n",
        "  def forward(self, x):\n",
        "    lstm_output, hidden = self.lstm(x)\n",
        "    nondropped = self.dropout(lstm_output)\n",
        "    output = self.fc(nondropped)\n",
        "    \n",
        "    return output\n",
        "  \n",
        "  \n",
        "\n",
        "print(model)\n",
        "pose_estimation = torch.FloatTensor(arr_frames)\n",
        "labels = torch.FloatTensor(arr_scores)\n",
        "\n",
        "epochs=3\n",
        "criterion = pearsonr\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "model = PoseLSTM()\n",
        "model_output = model.forward(pose_estimation)\n",
        "print(labels.shape)\n",
        "print(model_output.shape)\n",
        "print(model_output[0])\n",
        "for epoch in range(epochs):\n",
        "  # batch is not separated, because the size is small enough and I need to full gradient descent. \n",
        "\n",
        "  # 0. clear gradients\n",
        "  model.zero_grad()\n",
        "  # 1. get the output from the model\n",
        "  model_output = model.forward(pose_estimation)\n",
        "  \n",
        "  # 2. calculate the loss\n",
        "  loss = criterion(model_output, labels)\n",
        "  \n",
        "  # 3. call loss.backward()\n",
        "  loss.backward()\n",
        "  \n",
        "  # 4. update the parameters\n",
        "  optimizer.step()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PoseLSTM(\n",
            "  (lstm): LSTM(104, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5)\n",
            "  (fc): Linear(in_features=256, out_features=159, bias=True)\n",
            ")\n",
            "torch.Size([159])\n",
            "torch.Size([159, 202, 159])\n",
            "tensor([[ 0.0497, -0.0418,  0.0704,  ..., -0.0344,  0.0223,  0.0138],\n",
            "        [-0.0280, -0.0127,  0.0433,  ...,  0.0335, -0.0094, -0.0951],\n",
            "        [-0.1172, -0.0610,  0.2853,  ..., -0.0064,  0.0140, -0.0328],\n",
            "        ...,\n",
            "        [ 0.0496,  0.0671,  0.0835,  ..., -0.0422,  0.0732, -0.0354],\n",
            "        [ 0.0280,  0.0293,  0.0458,  ..., -0.0566,  0.0532,  0.0191],\n",
            "        [ 0.0139,  0.0314,  0.0682,  ..., -0.0404,  0.0606, -0.0487]],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-5fa78e7200f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;31m# 2. calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0;31m# 3. call loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-5fa78e7200f3>\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mxm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mr_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mr_den\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mr_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_num\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mr_den\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 3-D"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdfWo31XWqbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}